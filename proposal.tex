% !TeX program = xelatex

\documentclass[a4paper, 12pt]{article}

\usepackage{amsmath, mathtools}
\usepackage{blindtext}
\usepackage{fontspec}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{layout}
\usepackage[
    verbose,
    paper=a4paper,
    % showframe,
    left=1in,
    right=1in,
    top=36pt,
    textheight=698pt,
    headheight=16pt,
    headsep=20pt, %top+headh+heads=72pt
    marginparwidth=0pt,
    marginparsep=0pt,
    includeheadfoot]{geometry}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{titlesec}
\usepackage{xcolor}
\usepackage{array}
\usepackage{enumitem}

\mathtoolsset{showonlyrefs}

% Set main font
\setmainfont{Times New Roman}

% Header and Footer
\pagestyle{fancyplain}
\fancyhf{}
\pagenumbering{arabic}
\fancyhead[C]{
    \textbf{Momentum MSCA Programme - Call 2}
}
\fancyfoot[R]{\scriptsize
    page \thepage \,out of\, \pageref{LastPage}}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

\titleformat{\section}
    {\normalfont\bfseries}{\thesection.}{1em}{}

% Bibliography setup
\usepackage[
    style=ieee,
    backend=biber,
    url=false,
    doi=false,
    maxnames=4]{biblatex}
\addbibresource{refs.bib}
\defbibheading{bibliography}{\section*{References}}
\usepackage{setspace}

\def\CC{{C\nolinebreak[4]\hspace{-.05em}\raisebox{.2ex}{\scriptsize\bf ++}}}

\newcounter{objno}
\newcommand{\obj}[1]{\refstepcounter{objno}O.~\theobjno\label{#1}}

% For Work Packages list.
\newlist{WPs}{enumerate}{1}
\setlist[WPs]{label*=WP\arabic*:~,ref=WP.~\arabic*, align=left}
% \makeatletter
% \newcommand\myitem[1][]{%
%   \if\relax\detokenize{#1}\relax
%     \item\relax
%   \else
%     \protected@edef\@currentlabel{WP#1}%
%     \item[WP#1:~]
%   \fi}
\makeatother

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\begin{center}
\fbox{\parbox{0.98\textwidth}{\centering
\textbf{Research proposal}
}}
\end{center}

\begin{center}
    \renewcommand{\arraystretch}{1.6}
    \begin{tabular}{|p{0.26\textwidth}|p{0.68\textwidth}|}
        \hline
        Name of the Applicant: &
        Felipe Eduardo Ponce Vanegas \\
        \hline
        Application Title: &
        A Bayesian Approach to Nonlinear System Identification \\
        \hline
    \end{tabular}
\end{center}

\section{Excellence}

Reliable, autonomous, and smooth running machines is the most desirable state for any ma\-nu\-facturing plant.
To achieve, or approach, this utopian scenario it is essential to understand
the response of the machines to external forces so that
unstable operating conditions can be avoided or controlled.
To understand the response of a structure to external forces --- an activity known as System Identification ---
analysis of experimental data and modelling are essential components.

The general objective (GO) of this proposal is
\emph{to provide sound methods and algorithms for the analysis of experimental data
of structures with significant nonlinear effects.}
Here, we focus on structures encountered in Advance Manufacturing by metal removal operations,
like manufacturing of aerospace thin-walled components which
must comply with very high standards of quality and safety.
Nonlinear System Identification is an endless source of challenges, and
a growing field of research \cite{noel17}.

Unlike many successful data-driven models for image or language processing,
the amount of data available for training of models in Advance Manufacturing is much more limited.
To compensate for such scarcity of data (or relevant information),
physically motivated models are still in active use in the field, so
to achieve the GO I will follow this methodology.

Physical models of structures usually take the form
\begin{equation} \label{eq:mechanical_model}
    M\ddot{x} + C\dot{x} + Kx + G(t, x, \dot{x}) = f(t),
\end{equation}
where \(x\) are general coordinates of displacement from equilibrium,
\(f\) is an external force or excitation,
\(M\), \(C\), and \(K\) are matrices representing the mass, damping, and stiffness, and
\(G\) represents additional linear or nonlinear effects.
Linear models have been successfully applied in the modelling of many structures of practical interest, like machine tools.
However, in recent years, nonlinear effects are getting increasing attention
for, among other things, their relevance in lightweight structures \cite{martinelli24}, or
also for describing robot dynamics with varying parameters \cite{bjorn25}.
I remark that machining robots are a field of current interest in Advance Manufacturing \cite{verl19}.

As another methodological principle,
I plan to approach the subject from a Bayesian point of view, which
has not been thoroughly explored in this context.
Bayesian statistics offers a rigorous answer to the question:
to what extent do the collected data support a model?
This is the scientific question we want to answer from experiments, which
is in clear contrast with the popular Frequentist approach,
where a single model is assumed to be true, and
we have to find it by fitting parameters.
Bayesian statistics is particularly important when decisions must be made with little relevant information, and
we want to include modelling uncertainties into the predictions.

Bayes's theorem states that
\begin{equation} \label{eq:bayesT}
    p(M \,|\, D) \propto p(D \,|\, M)\,p(M),
\end{equation}
which means that the posterior, or conditional probability \(p(M \,|\, D)\) of a model \(M\) given the observed data or evidence \(D\), is
directly proportional to the likelihood, or conditional probability \(p(D \,|\, M)\) of the data given the model, times
the prior, or probability \(p(M)\) of the model.
The posterior \(p(M \,|\, D)\) is the central object to make predictions, and
Bayes's theorem is a method to compute it, but
the high computational cost makes Bayesian statistics unfeasible in many situations.
My ambitious plan is to make Bayesian inference a viable alternative,
in agreement with the GO, so
two strategic objectives are
\emph{to optimze the computation of the likelihood} (\obj{likelihood}), and
\emph{to enable model updating} (\obj{prior}).

The computation of the likelihood in O.~\ref{likelihood}
is roughly equivalent to efficiently solving \(x\) in \eqref{eq:mechanical_model} given the model parameters.
The computation of the posterior in \eqref{eq:bayesT} involves repeated computations of \(x\) with different parameters, which
are then plugged into the likelihood.
At each iteration, \(x\) may be found using traditional methods like
Runge--Kutta schemes, however,
this could lead to an excessive computational overhead.

Recently, novel methods inspired in data-driven algorithms have given way to a new ge\-ne\-ration of solvers which
could speed up the process dramatically.
Two popular methods are Physics-Informed Neural Networks (PINNs) \cite{pinn22}
and Sparse Identification of Non-linear Dynamics (SINDy) \cite{sindy19}.
In both cases
the idea is to train a model offline, and
then to use the trained model to retrieve solutions quickly.

PINNs solve differential equations by transforming them
into a loss minimization problem.
The solution \(x_\theta\) is approximated by a Neural Network with parameters \(\theta\), and
then \(\theta\) are adjusted by minimizing a loss function forcing
\(x_\theta\) to satisfy the differential equation.

SINDy replaces the dynamics by a sparse sum of nonlinear terms representing the main terms driving the system.
In an improved version of the method,
the solution \(x\) is mapped by an autoencoder to a space of lower dimension, which
gives a more fundamental representation of the solution.
This has a resemblance to the use of complex resonances and mode shapes for solving linear equations, which
effectively reduces \(x\) to a lower dimensional representation.
The initial cost of generating a dataset by solving the dynamics using standard numerical methods is later
recovered when new solutions must be quickly computed.

Another challenge when solving \eqref{eq:mechanical_model} is the
high dimensionality of \(x\) in many relevant cases.
To address this problem,
I can apply techniques like the Craig--Bamptom method, Reduction Order Models, Nonlinear Normal Modes \cite{cabre05}, among many other methods.
For instance, in \cite{conti23} Proper Orthogonal Decomposition (POD) was
used together with SINDy to efficiently track bifurcations in complex dynamical systems.

The Bayesian theoretical framework elegantly updates information using the posterior as the new prior when more data arrive.
Unfortunately,
technical issues make it difficult to realize this philosophy in practice,
forcing to re-train the model from scratch when new data arrive.
This renders Bayesian inference impractical for structures with varying parameters, and
to overcome this challenge is the core of O.~\ref{prior}.

The most reliable methods to explore the posterior are based on Markov Chain Monte Carlo (MCMC) algorithms \cite{gelman14}, which
approximate the posterior by returning samples from it.
State-of-the-art MCMC algorithms require the prior \(p(M)\) to be an analytic function, so
it is impossible to reuse a previous posterior because it is a collection of samples, not an analytic function.

Several alternatives have been put forward to solve this problem,
like sequential learning, or importance sampling.
Recently, Neural Networks have been proposed as a fast
alternative to computing probability densities.
For instance, in a problem of reconstruction of images from partial or corrupted data \cite{cai24},
samples were transformed into an analytic prior \(p(M)\) using a method called Normalizing Flow, which
uses Neural Networks to make a Gaussian distribution flow into another distribution.

The last strategic objective (\obj{experiment}) is
\emph{to validate a methodology experimentally.}
Objectives \ref{likelihood} and \ref{prior} give us a method to select promising models according to the evidence,
but it still remains to choose a structure and a experimental methodology.
There are plenty of possible structures, and a few relevant ones are listed in \cite{schoukens17}.
At first, a structure encounter in Advance Manufacturing will be used, like a thin-wall component or a robotic arm.

After setting the structure,
I will be assisted by my collaborators in the host and secondment institution for the experimental work.
In particular, tests will be designed to measure the extent of nonlinear effects, like
measuring the response at different amplitudes of excitation, and
frequency sweeps in both directions to detect backbone curves.

In agreement with Open Science policies,
I will upload submitted versions of the articles to the 
Repository of the Academy's Library (REAL), as encouraged by MTA, and also to arXiv.
Depending on the publisher's policies,
the accepted or published versions will be also deposited in the REAL;
no funds will be dedicated to the payment of open access fees.

MENTION INTERPRETABILITY.
TO SAY THAT THERE ARE MORE METHODS, AND I AM NOT LIMITED TO THOSE I MENTIONED.

For the scientific code,
I will give priority to open-source software, and
I will upload the code to public repositories, like GitHub.
Experimental datasets will be uploaded to the repository of the
Hungarian Research Network (HUN-REN).
For more details, see the Data Management Plan.


\section{Impact}

Nonlinear System Identification is a very complex problem, and
it may define my whole future academic career.
In the medium term,
securing this prestigious grant will increase my visibility and
probabilities of success in securing further funding for my research or scientific events.
Since this project may yield algorithms with industrial relevance,
in the future I could serve as a consultant in areas like advanced manufacturing.

In the short term,
I will benefit from the interaction with the members of
the Machine Tool Vibration Research Group (MTV-RG) and their large list of collaborators.
The MTV-RG is known for their sensitivity when it comes to appreciate the mathematical depth behind manufacturing processes
(which is not always the case in engineering environments),
so the MTV-RG is the right place to learn and apply several mathematical techniques in high demand inside and outside academia.

For example, I have only learned about NNs in theory, but
I lack practical experience, so
this project will serve as a hands-on training on NNs.
Also, I do not have much experience performing FEM simulations,
but for this project I may need to simulate complex structures, which
will force me to enhance my skills on this area.

Bayesian statistics is conceptually and computationally more demanding than the standard Frequentist statistics,
so researching in this area will make me stand out among my scientific peers.
It is worth noting that I will also gain more experience in data man\-age\-ment and analysis.
For example, I still have more to learn about FAIR principles and data versioning.

I plan to develop an open-source Python package ---
inspired by the principles of NumPy and similar scientific packages ---
where I will collect, organize, and maintain algorithms so that
other researchers or industrial R\&D teams can exploit them,
facilitating technology transfer.
Additionally, software maintenance demands several skills to enable an effective interaction with the users, like
a well-documented code, a webpage, and a pipeline from development to deployment.
For all this, I will take a course on good practices for code development and deployment.

Frequentist statistics is still the main method of analysis in many areas, even
in conditions where it cannot be fully justified.
This project will promote the use of Bayesian statistics for the analysis of industrial processes
through the introduction of robust algorithms together with their implementation in use-cases.
As mentioned in the first section,
one of the bottlenecks in the application of Bayesian methods is
the difficulty of converting a posterior into a prior for further sampling.
However, this project seeks to solve this problem,
at least for specific cases that may hint a more general method for future research.

Advanced Manufacturing is a strategic sector
for maintaining Europe's position as a competitive global player.
Autonomous factories performing at optimum levels while maintaining the highest standards of quality and safety
is the goal of any company that expect to stay competitive.
However, to approach this ideal state,
we still need to understand the response of the machines to external forces and
to be able to steer them to stable conditions.

Modal Analysis has been an essential part for the ma\-nu\-facturing industry for years in
the understanding of response functions and modelling of processes, but
it only applies to linear structures, which not only limit its scope of applicability but
also limit our ability to design and deploy nonlinear structures for which
we do not understand their response.

The new theoretical frameworks and methodologies developed during this project will
contribute to the creation of new tools for monitoring, control, and diagnosis of machining processes where
nonlinear effects and varying parameters play an important role.
Furthermore, the use of Bayesian statistics allows quantifying model uncertainties,
which renders more reliable predictions than usual frequentist methods.

Research outputs will be disseminated through the usual scientific channels:
articles in re\-pu\-table peer-reviewed journals, and
posters and talks in scientific events.
Additionally, the research outputs will be promoted through the webpages of the Department of Applied Mechanics and the MTV-RG.
I will also post in my webpage blog entries featuring my research or interesting facts in a more engaging and less formal language for a broader scientific audience.

To grow and strengthen my collaborative network,
I will organize at least one workshop on Nonlinear System Identification and Bayesian statistics to bring together researchers
from both fields.


\section{Implementation}

As a MSCA fellow,
I will be part of the MTA-BME Lendület MTV-RG, led by Zoltán Dombóvári, 
which functions within the Department of Applied Mecha\-nics.
The main objective of the MTV-RG is to
develop a framework for effective intervention of machining processes based on sensory data.
Among the strategic objectives,
robot dynamics and machining of slender workpieces feature prominently due to
the emergence of nonlinear behavior and time varying parameters,
which perfectly aligns with the objectives of this proposal,
although the approaches are different.

I will bring to the MTV-RG a Bayesian perspective which
they have not explored yet.
This new perspective will extend the MTV-RG's research portfolio
by endowing them with new tools for the rigorous statistical analysis of experimental data, and
additional theoretical knowledge for including uncertainty into their models.

The MTV-RG excels at the construction, simulation, and experimental validation of physical models of machining processes.
However, at times, their work depends on the application of heuristic algorithms or black-boxes
whose inner workings do not lie in their domain of expertise.
On the other hand, as a mathematician,
I rely on their expert knowledge and experience on machining processes.
This creates a perfect synergy because
I can complement them by opening and modifying black-boxes (like NN architectures) tailored
for specific use-cases, while
steering my work toward physically relevant mathematical concepts.

\textcolor{red}{Does BME-MM have access to any computing cluster?}

\textcolor{red}{Does BME-MM have licenses for relevant programs, like: Ansys, Siemens Testlab, Matlab, Abaqus, ...}

\textcolor{red}{About equipment and facilities, what do you suggest I should remark as strengths of MM-BME.}

\textcolor{red}{Describe the resources required for your project.
Detail any specific equipment, datasets, capabilities, or facilities needed}

A secondment is planned at the Royal Institute of Technology (KTH) in Stockholm, Sweden,
under the supervision of Andreas Archenti, 
a well-known researcher in precision engineering.
Other collaborators in the Basque Country, Spain, are:
\textit{(i)} The Basque Center for Applied Mathematics (BCAM);
\textit{(ii)} The Aeronautics Advanced Manufacturing Center (CFAA); and
\textit{(iii)} IDEKO.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\textwidth]{images/gantt.eps}
    \caption{Gantt chart. Abbreviations: Experiments (Exp); Python Package (Pkg); Workshop (WS); and Secondment (S).
    Red bar denotes third-party responsibility. \textcolor{red}{correct S}}\label{fig:gantt}
\end{figure}


The Work Packages (WP), Milestones (MS), and Deliverables (D) of the project, summarized in Figure~\ref{fig:gantt}, are:

\begin{WPs}[
    topsep=\parskip, itemsep=\parskip, parsep=\parskip,
    leftmargin=10pt, itemindent=!]

    \item \textit{Project management:}
    Management activities to ensure that the project reaches its completion, including progress reports requested by the funding agencies.

    MS.~1: Kick-off meeting;
    MS.~2: First version of the Data Management Plan (DMP); and
    MS.~3: Secondment finished.

    D.~1: Meeting report;
    D.~2: Upload DMP to repository; and
    D.~3: Certificate of stay from secondment institution.

    \item \textit{Solving dynamical systems:}
    Activities to reach O.~\ref{likelihood}.

    MS.~1: Efficiently solve dynamical systems of interest using existing or novel methods.

    D.~1: Scientific article.

    \item \textit{Model updating:}
    Activities to reach O.~\ref{prior}.

    MS.~1: Implement and apply an algorithm to approach target probability densities.

    D.~1: Scientific article.

    \item \textit{Experimental validation:}
    Activities to reach O.~\ref{experiment}.
    Find a source of data, either existing datasets or
    data from a new experiment.
    In the latter case, design and perform the experiment,
    collect data, and analyze them.

    MS.~1: Define data source; and
    MS.~2: Apply a methodology for Nonlinear System Identification using Bayesian inference to a specific dataset.

    D.~1: If the dataset is new, upload it to repository; and
    D.~2: Scientific article.

    \item \textit{Dissemination and Transfer Knowledge:}
    Activities to create synergies with researchers at the host institution, and to reach academic and industrial partners.

    MS.~1: First version of Python package; and
    MS.~2: Successful conclusion of workshop.

    D.~1: Publish package's repository and website; and
    D.~2: Workshop proceedings.

\end{WPs}

\begin{table}[t!]
    \centering
    % \renewcommand{\arraystretch}{1.}
    \caption{
    Risks and mitigation actions;
    only technical risks, ignoring familiar or inter-personal risks.
    The Likelihood/Impact (\textbf{L/I}) is described as Low (L), Medium (M), or High (H).}\label{tab:risks}
    \begin{tabular}{@{}
        >{\centering\arraybackslash}p{.05\textwidth-2\tabcolsep}
        p{.36\textwidth-2\tabcolsep}
        >{\centering\arraybackslash}p{.07\textwidth-2\tabcolsep}
        p{.54\textwidth-2\tabcolsep}
    @{}}
        \toprule
        \textbf{\footnotesize WP} &
        \multicolumn{1}{c}{\textbf{Risk}} &
        \textbf{L/I} &
        \multicolumn{1}{c}{\textbf{Mitigation}} \\
        \midrule

        1 &
        No secondment institution is found. &
        L/H &
        A. Archenti (KTH)
        has expressed his willingness to accept me as a mentee.
        Another alternative is IDEKO, Spain.
        Also, Z. Dombóvári has an extense list of collaborators.
         \\ \midrule

        2 &
        The new algorithms are not sufficiently fast for Bayesian exploration. &
        M/H &
        WP3 depends on this.
        Define a hierarchy of models, from simple to complex, so that
        at each stage there is only one major issue to overcome
        like a nonlinearity or high-dimensionality.
        Leverage computational speed and complexity. \\ \midrule

        3 &
        The algorithm is prohibitively slow, or
        the posteior do not converge to the target distribution. &
        M/M &
        WP4 depends on this, but
        MCMC can still be used for simple models in WP4.
        Again, use a hierarchy of models. \\ \midrule

        4 &
        No sufficient funding for experiments,
        experiments cannot be completed, or
        bad results (\textit{e.g.} malfunctioning sensor). &
        H/H &
        Fall back to historical data from a collaborator like IDEKO or CFAA, or
        publicly available datasets.
        \\ \midrule

        4 &
        No dataset provided by any collaborator, or
        it is not usable (\textit{e.g.} low quality, irrelevant data). &
        M/H &
        Resort to simulated data.
        The project can still be completed, but
        with weaker conclusions. \\

        % 5 &
        % Problems organizing the workshop
        % (\textit{e.g.} delays, unexpected cancellations, low attendance) &
        % M/L &
        % I do not have much experience as organizer, but
        % Z. Dombóvári do.
        % The workshop could be online.
        % If no workshop takes place,
        % it would undermine the dissemination plan, but
        % I still will share the outputs through articles, congreses, etc. \\

        \bottomrule
    \end{tabular}
\end{table}

\noindent The risks and mitigation actions are described in Table~\ref{tab:risks}.


\begingroup
\setlength\bibitemsep{0pt}
\printbibliography

\end{document}